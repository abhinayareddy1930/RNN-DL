{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "c0MWq4BLd_4m"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, GRU, SimpleRNN, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dakshina_pairs(filepath, num_samples=None):\n",
        "    with open(filepath, 'r', encoding='utf-8') as f:\n",
        "        lines = f.read().strip().split('\\n')\n",
        "    pairs = [line.split('\\t') for line in lines]\n",
        "    if num_samples:\n",
        "        pairs = pairs[:num_samples]\n",
        "    return [(latin, '<start> ' + devanagari + ' <end>') for latin, devanagari in pairs]\n"
      ],
      "metadata": {
        "id": "QY9Oqgd9ex0y"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import unicodedata\n",
        "import string\n",
        "import os\n",
        "import random\n",
        "\n",
        "# ---------------------\n",
        "# CONFIGURATION\n",
        "# ---------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "EMBEDDING_DIM = 64\n",
        "HIDDEN_DIM = 128\n",
        "NUM_LAYERS = 1\n",
        "CELL_TYPE = 'LSTM'  # Options: 'RNN', 'LSTM', 'GRU'\n",
        "BATCH_SIZE = 32\n",
        "NUM_EPOCHS = 15\n",
        "TEACHER_FORCING_RATIO = 0.5\n",
        "MAX_LENGTH = 30\n",
        "\n",
        "# ---------------------\n",
        "# DATA LOADING AND PREPROCESSING\n",
        "# ---------------------\n",
        "class TransliterationDataset(Dataset):\n",
        "    def __init__(self, path):\n",
        "        self.pairs = []\n",
        "        self.input_chars = set()\n",
        "        self.output_chars = set()\n",
        "\n",
        "        with open(path, 'r', encoding='utf-8') as f:\n",
        "            for line in f:\n",
        "                latin, devanagari = line.strip().split('\\t')\n",
        "                self.pairs.append((latin, devanagari))\n",
        "                self.input_chars.update(latin)\n",
        "                self.output_chars.update(devanagari)\n",
        "\n",
        "        self.input_chars = sorted(list(self.input_chars))\n",
        "        self.output_chars = sorted(list(self.output_chars))\n",
        "\n",
        "        self.input_char2idx = {ch: i + 1 for i, ch in enumerate(self.input_chars)}\n",
        "        self.output_char2idx = {ch: i + 1 for i, ch in enumerate(self.output_chars)}\n",
        "\n",
        "        self.input_char2idx['<pad>'] = 0\n",
        "        self.output_char2idx['<pad>'] = 0\n",
        "        self.output_char2idx['<sos>'] = len(self.output_char2idx)\n",
        "        self.output_char2idx['<eos>'] = len(self.output_char2idx)\n",
        "\n",
        "        self.input_idx2char = {i: ch for ch, i in self.input_char2idx.items()}\n",
        "        self.output_idx2char = {i: ch for ch, i in self.output_char2idx.items()}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "\n",
        "    def encode_seq(self, seq, char2idx, add_sos_eos=False):\n",
        "        indices = [char2idx[c] for c in seq]\n",
        "        if add_sos_eos:\n",
        "            indices = [char2idx['<sos>']] + indices + [char2idx['<eos>']]\n",
        "        return indices\n",
        "\n",
        "    def pad_seq(self, indices, max_length):\n",
        "        return indices + [0] * (max_length - len(indices))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_seq, target_seq = self.pairs[idx]\n",
        "        input_encoded = self.encode_seq(input_seq, self.input_char2idx)\n",
        "        target_encoded = self.encode_seq(target_seq, self.output_char2idx, add_sos_eos=True)\n",
        "\n",
        "        input_encoded = self.pad_seq(input_encoded, MAX_LENGTH)\n",
        "        target_encoded = self.pad_seq(target_encoded, MAX_LENGTH + 2)\n",
        "\n",
        "        return (\n",
        "            torch.tensor(input_encoded, dtype=torch.long),\n",
        "            torch.tensor(target_encoded, dtype=torch.long)\n",
        "        )\n",
        "\n",
        "# ---------------------\n",
        "# MODEL DEFINITION\n",
        "# ---------------------\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, embedding_dim, hidden_dim, num_layers, cell_type='LSTM'):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(input_size, embedding_dim, padding_idx=0)\n",
        "        rnn_cell = getattr(nn, cell_type)\n",
        "        self.rnn = rnn_cell(embedding_dim, hidden_dim, num_layers, batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        outputs, hidden = self.rnn(embedded)\n",
        "        return outputs, hidden\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_size, embedding_dim, hidden_dim, num_layers, cell_type='LSTM'):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(output_size, embedding_dim, padding_idx=0)\n",
        "        rnn_cell = getattr(nn, cell_type)\n",
        "        self.rnn = rnn_cell(embedding_dim, hidden_dim, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        x = x.unsqueeze(1)\n",
        "        embedded = self.embedding(x)\n",
        "        output, hidden = self.rnn(embedded, hidden)\n",
        "        prediction = self.fc(output.squeeze(1))\n",
        "        return prediction, hidden\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, cell_type='LSTM'):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.cell_type = cell_type\n",
        "\n",
        "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
        "        batch_size = src.size(0)\n",
        "        trg_len = trg.size(1)\n",
        "        trg_vocab_size = self.decoder.fc.out_features\n",
        "\n",
        "        outputs = torch.zeros(batch_size, trg_len, trg_vocab_size).to(device)\n",
        "\n",
        "        encoder_outputs, hidden = self.encoder(src)\n",
        "\n",
        "        input = trg[:, 0]  # <sos> token\n",
        "\n",
        "        for t in range(1, trg_len):\n",
        "            output, hidden = self.decoder(input, hidden)\n",
        "            outputs[:, t] = output\n",
        "            top1 = output.argmax(1)\n",
        "            input = trg[:, t] if random.random() < teacher_forcing_ratio else top1\n",
        "\n",
        "        return outputs\n",
        "\n",
        "# ---------------------\n",
        "# TRAINING AND EVALUATION\n",
        "# ---------------------\n",
        "def train_model(model, dataloader, criterion, optimizer):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for src, trg in dataloader:\n",
        "        src, trg = src.to(device), trg.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src, trg, TEACHER_FORCING_RATIO)\n",
        "\n",
        "        output_dim = output.shape[-1]\n",
        "        output = output[:, 1:].reshape(-1, output_dim)\n",
        "        trg = trg[:, 1:].reshape(-1)\n",
        "\n",
        "        loss = criterion(output, trg)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "def evaluate_model(model, dataloader, dataset):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    sample_outputs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for src, trg in dataloader:\n",
        "            src = src.to(device)\n",
        "            outputs = model(src, trg=None, teacher_forcing_ratio=0)\n",
        "\n",
        "            preds = outputs.argmax(2).cpu().numpy()\n",
        "            for i in range(src.size(0)):\n",
        "                pred_seq = preds[i]\n",
        "                gold_seq = trg[i].cpu().numpy()\n",
        "                pred_chars = [dataset.output_idx2char[idx] for idx in pred_seq if idx != 0 and idx not in [dataset.output_char2idx['<sos>'], dataset.output_char2idx['<eos>']]]\n",
        "                gold_chars = [dataset.output_idx2char[idx] for idx in gold_seq if idx != 0 and idx not in [dataset.output_char2idx['<sos>'], dataset.output_char2idx['<eos>']]]\n",
        "\n",
        "                if pred_chars == gold_chars:\n",
        "                    correct += 1\n",
        "                total += 1\n",
        "                if len(sample_outputs) < 5:\n",
        "                    input_str = ''.join([dataset.input_idx2char[idx.item()] for idx in src[i] if idx.item() != 0])\n",
        "                    sample_outputs.append((input_str, ''.join(gold_chars), ''.join(pred_chars)))\n",
        "\n",
        "    accuracy = correct / total * 100\n",
        "    return accuracy, sample_outputs\n",
        "\n",
        "# ---------------------\n",
        "# MAIN TRAINING LOOP\n",
        "# ---------------------\n",
        "def run_training(data_path):\n",
        "    dataset = TransliterationDataset(data_path)\n",
        "    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "    encoder = Encoder(\n",
        "        input_size=len(dataset.input_char2idx),\n",
        "        embedding_dim=EMBEDDING_DIM,\n",
        "        hidden_dim=HIDDEN_DIM,\n",
        "        num_layers=NUM_LAYERS,\n",
        "        cell_type=CELL_TYPE\n",
        "    ).to(device)\n",
        "\n",
        "    decoder = Decoder(\n",
        "        output_size=len(dataset.output_char2idx),\n",
        "        embedding_dim=EMBEDDING_DIM,\n",
        "        hidden_dim=HIDDEN_DIM,\n",
        "        num_layers=NUM_LAYERS,\n",
        "        cell_type=CELL_TYPE\n",
        "    ).to(device)\n",
        "\n",
        "    model = Seq2Seq(encoder, decoder, cell_type=CELL_TYPE).to(device)\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "    optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        loss = train_model(model, dataloader, criterion, optimizer)\n",
        "        print(f\"Epoch {epoch + 1}/{NUM_EPOCHS}, Loss: {loss:.4f}\")\n",
        "\n",
        "    accuracy, samples = evaluate_model(model, dataloader, dataset)\n",
        "    print(f\"\\n✅ Final Accuracy: {accuracy:.2f}%\")\n",
        "    print(\"\\n🔤 Sample Predictions:\")\n",
        "    for i, (inp, tgt, pred) in enumerate(samples):\n",
        "        print(f\"{i+1}. {inp} ➡️ {pred} (Target: {tgt})\")\n",
        "\n",
        "# ---------------------\n",
        "# RUN IT\n",
        "# ---------------------\n",
        "# Example: 'data/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.train.tsv'\n",
        "run_training(\"PATH_TO_TRAIN_FILE\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "q9OrhIg-gEvm",
        "outputId": "dd60305e-751b-48e0-b5fd-8ec6cd038d0b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'PATH_TO_TRAIN_FILE'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-1ad7b9a37410>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;31m# ---------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;31m# Example: 'data/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.train.tsv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m \u001b[0mrun_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"PATH_TO_TRAIN_FILE\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-1ad7b9a37410>\u001b[0m in \u001b[0;36mrun_training\u001b[0;34m(data_path)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;31m# ---------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransliterationDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m     \u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-1ad7b9a37410>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_chars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0mlatin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevanagari\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'PATH_TO_TRAIN_FILE'"
          ]
        }
      ]
    }
  ]
}